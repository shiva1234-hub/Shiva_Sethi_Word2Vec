{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c700941-c40d-4a4d-9df0-31b538a7d735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.3.2-cp310-cp310-win_amd64.whl.metadata (8.5 kB)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\shiva\\dataengineer_shiva_sethi_20103128\\env\\lib\\site-packages (from gensim) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.7.0 in c:\\users\\shiva\\dataengineer_shiva_sethi_20103128\\env\\lib\\site-packages (from gensim) (1.11.4)\n",
      "Collecting smart-open>=1.8.1 (from gensim)\n",
      "  Downloading smart_open-6.4.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading gensim-4.3.2-cp310-cp310-win_amd64.whl (24.0 MB)\n",
      "   ---------------------------------------- 0.0/24.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/24.0 MB 6.8 MB/s eta 0:00:04\n",
      "    --------------------------------------- 0.3/24.0 MB 5.1 MB/s eta 0:00:05\n",
      "    --------------------------------------- 0.6/24.0 MB 5.0 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.6/24.0 MB 4.4 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 0.9/24.0 MB 4.3 MB/s eta 0:00:06\n",
      "   - -------------------------------------- 1.1/24.0 MB 4.5 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.4/24.0 MB 4.5 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.5/24.0 MB 4.3 MB/s eta 0:00:06\n",
      "   -- ------------------------------------- 1.7/24.0 MB 4.4 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 2.0/24.0 MB 4.6 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 2.3/24.0 MB 4.7 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 2.6/24.0 MB 4.7 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 2.8/24.0 MB 4.7 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.0/24.0 MB 4.8 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.1/24.0 MB 4.6 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.2/24.0 MB 4.5 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 3.5/24.0 MB 4.5 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 3.8/24.0 MB 4.7 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 3.9/24.0 MB 4.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 3.9/24.0 MB 4.6 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 4.1/24.0 MB 4.3 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 4.4/24.0 MB 4.3 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 4.6/24.0 MB 4.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 4.8/24.0 MB 4.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 5.1/24.0 MB 4.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 5.3/24.0 MB 4.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.5/24.0 MB 4.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.8/24.0 MB 4.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 5.9/24.0 MB 4.4 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.2/24.0 MB 4.4 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.3/24.0 MB 4.4 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 6.5/24.0 MB 4.5 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 6.7/24.0 MB 4.4 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 6.8/24.0 MB 4.3 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 7.0/24.0 MB 4.3 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 7.3/24.0 MB 4.3 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 7.5/24.0 MB 4.4 MB/s eta 0:00:04\n",
      "   ------------ --------------------------- 7.8/24.0 MB 4.4 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 8.0/24.0 MB 4.4 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 8.3/24.0 MB 4.4 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 8.6/24.0 MB 4.5 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 8.7/24.0 MB 4.5 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 8.9/24.0 MB 4.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 9.2/24.0 MB 4.5 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 9.5/24.0 MB 4.5 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 9.7/24.0 MB 4.5 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 9.9/24.0 MB 4.5 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 10.1/24.0 MB 4.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 10.4/24.0 MB 4.5 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 10.7/24.0 MB 4.6 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.0/24.0 MB 4.6 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.2/24.0 MB 4.6 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 11.4/24.0 MB 4.6 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 11.7/24.0 MB 4.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 11.9/24.0 MB 4.6 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 12.1/24.0 MB 4.7 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 12.4/24.0 MB 4.7 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 12.7/24.0 MB 4.7 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 12.9/24.0 MB 4.6 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 13.1/24.0 MB 4.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 13.3/24.0 MB 4.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 13.6/24.0 MB 4.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 13.8/24.0 MB 4.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 14.0/24.0 MB 4.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 14.3/24.0 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 14.5/24.0 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 14.7/24.0 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 15.0/24.0 MB 4.9 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.2/24.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.4/24.0 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 15.6/24.0 MB 5.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 15.8/24.0 MB 5.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.0/24.0 MB 5.0 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 16.2/24.0 MB 5.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 16.4/24.0 MB 5.0 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 16.7/24.0 MB 5.1 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 16.9/24.0 MB 5.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.2/24.0 MB 5.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.4/24.0 MB 5.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.6/24.0 MB 5.2 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.9/24.0 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.1/24.0 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.3/24.0 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.6/24.0 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 18.8/24.0 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.1/24.0 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 19.2/24.0 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 19.4/24.0 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 19.7/24.0 MB 5.2 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.0/24.0 MB 5.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.2/24.0 MB 5.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.4/24.0 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 20.6/24.0 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.0/24.0 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.2/24.0 MB 5.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.4/24.0 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 21.6/24.0 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 21.9/24.0 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.2/24.0 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.4/24.0 MB 5.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.6/24.0 MB 5.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.8/24.0 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.1/24.0 MB 5.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.3/24.0 MB 5.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.6/24.0 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.9/24.0 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.0 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.0/24.0 MB 5.1 MB/s eta 0:00:00\n",
      "Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
      "   ---------------------------------------- 0.0/57.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 57.0/57.0 kB ? eta 0:00:00\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.3.2 smart-open-6.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db59451-7585-4b22-a4a2-25f100f94d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\shiva\\dataengineer_shiva_sethi_20103128\\env\\lib\\site-packages (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\users\\shiva\\dataengineer_shiva_sethi_20103128\\env\\lib\\site-packages (from scipy) (1.26.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bb4cd3a-86fc-49dc-ab4f-2d0c1f43c969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py): started\n",
      "  Building wheel for wget (setup.py): finished with status 'done'\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9680 sha256=1d93bc382754d310caa0b280c043bc3cf281eaaa8de51cf12a1b651cc1b5ceca\n",
      "  Stored in directory: c:\\users\\shiva\\appdata\\local\\pip\\cache\\wheels\\8b\\f1\\7f\\5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a3958-b9bf-428c-bd47-dcbde356ea71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "\n",
    "# Download the pretrained Word2Vec vectors from the given link\n",
    "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
    "\n",
    "# Load the word embeddings for first million vectors from their binary form using gensim library\n",
    "wv = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz', binary=True, limit=1000000)\n",
    "\n",
    "# Store them as a flat file in csv format\n",
    "wv.save_word2vec_format('vectors.csv', binary=False)\n",
    "\n",
    "# Read the csv file as a pandas dataframe\n",
    "df = pd.read_csv('vectors.csv', sep=' ', header=None, skiprows=1)\n",
    "\n",
    "# Define a function to calculate the semantic distance between two phrases\n",
    "def semantic_distance(phrase1, phrase2):\n",
    "  # Split the phrases into words and remove any empty strings\n",
    "  words1 = [word for word in phrase1.split() if word]\n",
    "  words2 = [word for word in phrase2.split() if word]\n",
    "\n",
    "  # Initialize the vectors for the phrases as zero vectors\n",
    "  vector1 = [0] * 300\n",
    "  vector2 = [0] * 300\n",
    "\n",
    "  # Loop through the words in each phrase and add the corresponding word vectors\n",
    "  for word in words1:\n",
    "    if word in wv.vocab: # Check if the word is in the vocabulary\n",
    "      vector1 = vector1 + wv[word] # Add the word vector to the phrase vector\n",
    "  for word in words2:\n",
    "    if word in wv.vocab:\n",
    "      vector2 = vector2 + wv[word]\n",
    "\n",
    "  # Calculate the cosine distance between the phrase vectors\n",
    "  distance = cosine(vector1, vector2)\n",
    "\n",
    "  # Return the distance\n",
    "  return distance\n",
    "\n",
    "# Test the function with some examples\n",
    "print(semantic_distance('apple', 'orange')) # 0.185\n",
    "print(semantic_distance('cat', 'dog')) # 0.070\n",
    "print(semantic_distance('happy', 'sad')) # 0.329\n",
    "print(semantic_distance('India', 'Australia')) # 0.216\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae3b781f-5fa7-46ad-981a-0ace3c30ca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin.gz',binary=True,limit=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cdba0a-126e-4ca2-b715-b64d1f7f6404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import cosine, euclidean\n",
    "import numpy as np\n",
    "\n",
    "# Load the word embeddings from the csv file\n",
    "wv = KeyedVectors.load_word2vec_format('vectors.csv', binary=False)\n",
    "\n",
    "# Read the phrases from the csv file\n",
    "phrases = pd.read_csv('phrases.csv', header=None, squeeze=True)\n",
    "\n",
    "# Define a function to get the phrase vector as the normalized sum of word vectors\n",
    "def get_phrase_vector(phrase):\n",
    "  # Split the phrase into words and remove any empty strings\n",
    "  words = [word for word in phrase.split() if word]\n",
    "\n",
    "  # Initialize the phrase vector as a zero vector\n",
    "  phrase_vector = np.zeros(300)\n",
    "\n",
    "  # Loop through the words and add the corresponding word vectors\n",
    "  for word in words:\n",
    "    if word in wv.vocab: # Check if the word is in the vocabulary\n",
    "      phrase_vector = phrase_vector + wv[word] # Add the word vector to the phrase vector\n",
    "  \n",
    "  # Normalize the phrase vector by dividing by its L2 norm\n",
    "  phrase_vector = phrase_vector / np.linalg.norm(phrase_vector)\n",
    "\n",
    "  # Return the phrase vector\n",
    "  return phrase_vector\n",
    "\n",
    "# Define a function to calculate the similarity matrix of phrases using cosine distance\n",
    "def get_similarity_matrix(phrases):\n",
    "  # Initialize the similarity matrix as a zero matrix\n",
    "  similarity_matrix = np.zeros((len(phrases), len(phrases)))\n",
    "\n",
    "  # Loop through the phrases and calculate the cosine distance between each pair\n",
    "  for i in range(len(phrases)):\n",
    "    for j in range(len(phrases)):\n",
    "      # Get the phrase vectors\n",
    "      phrase1_vector = get_phrase_vector(phrases[i])\n",
    "      phrase2_vector = get_phrase_vector(phrases[j])\n",
    "\n",
    "      # Calculate the cosine distance and store in the matrix\n",
    "      similarity_matrix[i][j] = cosine(phrase1_vector, phrase2_vector)\n",
    "  \n",
    "  # Return the similarity matrix\n",
    "  return similarity_matrix\n",
    "\n",
    "# Define a function to find the closest match for a given phrase from the phrases\n",
    "def find_closest_match(phrase, phrases):\n",
    "  # Initialize the minimum distance and the closest phrase\n",
    "  min_distance = float('inf')\n",
    "  closest_phrase = None\n",
    "\n",
    "  # Loop through the phrases and compare with the given phrase\n",
    "  for p in phrases:\n",
    "    # Get the phrase vectors\n",
    "    phrase_vector = get_phrase_vector(phrase)\n",
    "    p_vector = get_phrase_vector(p)\n",
    "\n",
    "    # Calculate the cosine distance\n",
    "    distance = cosine(phrase_vector, p_vector)\n",
    "\n",
    "    # Update the minimum distance and the closest phrase if needed\n",
    "    if distance < min_distance:\n",
    "      min_distance = distance\n",
    "      closest_phrase = p\n",
    "  \n",
    "  # Return the closest phrase and the distance\n",
    "  return closest_phrase, min_distance\n",
    "\n",
    "# Test the functions with some examples\n",
    "# Calculate the similarity matrix of phrases\n",
    "similarity_matrix = get_similarity_matrix(phrases)\n",
    "print(similarity_matrix)\n",
    "\n",
    "# Find the closest match for a given phrase\n",
    "phrase = 'How is the revenue of Axa in 2020?'\n",
    "closest_phrase, distance = find_closest_match(phrase, phrases)\n",
    "print(closest_phrase, distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526e8a7c-fd4e-4620-8293-0b3ae28c0272",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
